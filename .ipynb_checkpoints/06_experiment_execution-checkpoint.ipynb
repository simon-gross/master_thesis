{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23cd1c09-b018-4dc9-b623-8afc0bcea337",
   "metadata": {},
   "source": [
    "# Experiment Execution\n",
    "The notebook executes the experiment by sending all experiment calls to the OpenAI API and recording all parameters such as temperature or the used ontology.\n",
    "\n",
    "The full experiment takes a lot of time to run because of the large amout of sample questions. Thats why here only the first 18 questions are taken as an example to run to showcase the functionality. The subsequent notebooks are then executed using this data from the studies experiment.\n",
    "\n",
    "The experiment is run each step at a time with saving backups inbetween. Each step is only run if the file for its backup does not exist yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e45c6c-c825-4905-932e-e40839580130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "from rdflib import Graph\n",
    "from itertools import product\n",
    "from functions.nlp import populate_question\n",
    "from functions.sparql_requests import sparql_select, clean_query, optimize_buffer, replace_directions_python\n",
    "from functions.general_functions import pickleload, pickledump\n",
    "from functions.llm_functions import run_client_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d40e7c-745f-4d9f-b679-fbeed133f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2ccc4-bf76-4dcf-b697-c09c3559f01a",
   "metadata": {},
   "source": [
    "# Load non-populated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0eb13b2-79e1-4200-818b-81f18ed84ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"data/examples_not_populated.pkl\"\n",
    "not_populated = pickleload(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8ae66-b32f-49f0-a566-9099f41612d8",
   "metadata": {},
   "source": [
    "# Populate for non-RAG experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0a1f7-12be-440a-8f42-17c73de444ce",
   "metadata": {},
   "source": [
    "### Set up Ontologies and Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "929991d5-9f0c-482e-ad33-f48567d01ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_g = Graph()\n",
    "ontology_g.parse(\"data/ontology_full_v1.ttl\", format=\"turtle\")\n",
    "ontology = ontology_g.serialize(format=\"turtle\")\n",
    "\n",
    "ontology_g2 = Graph()\n",
    "ontology_g2.parse(\"data/ontology_full_v2.ttl\", format=\"turtle\")\n",
    "ontology2 = ontology_g2.serialize(format=\"turtle\")\n",
    "\n",
    "ontology_g3 = Graph()\n",
    "ontology_g3.parse(\"data/ontology_full_v3.ttl\", format=\"turtle\")\n",
    "ontology3 = ontology_g3.serialize(format=\"turtle\")\n",
    "\n",
    "sysmsg_tips = \"You are an AI assistant that translates natural language questions about geospatial relations into SPARQL queries based on the given Ontology. Your answer should only contain the SPARQL query. Keep in mind that geofunctions can only be used with a WKT literal that is attached to a geometry subject: '?geom geo:asWKT ?wkt'\"\n",
    "sysmsg = \"You are an AI assistant that translates natural language questions about geospatial relations into SPARQL queries based on the given Ontology. Your answer should only contain the SPARQL query.\"\n",
    "sysmsg_new_tips = \"\"\"You are an AI assistant that writes SPARQL queries to a graph database based on a user question and the graphs' ontology. The questions are about the location and topology of the graphs elements. Your answer should only contain the SPARQL query. Keep in mind that geofunctions can only be used with a WKT literal that is attached to a geometry subject: '?geom geo:asWKT ?wkt'\"\"\"\n",
    "sysmsg_new =      \"\"\"You are an AI assistant that writes SPARQL queries to a graph database based on a user question and the graphs' ontology. The questions are about the location and topology of the graphs elements. Your answer should only contain the SPARQL query. Keep in mind that geofunctions can only be used with a WKT literal that is attached to a geometry subject: '?geom geo:asWKT ?wkt'\"\"\"\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "Write a SPARQL SELECT query for querying a graph database.\n",
    "The ontology schema delimited by triple backticks in Turtle format is:\n",
    "```\n",
    "{}\n",
    "```\n",
    "Use only the classes and properties provided in the schema to construct the SPARQL query.\n",
    "Do not use any classes or properties that are not explicitly provided in the SPARQL query.\n",
    "Include all necessary prefixes.\n",
    "Do not include any explanations or apologies in your responses.\n",
    "Do not wrap the query in backticks.\n",
    "Do not include any text except the SPARQL query generated.\n",
    "The question delimited by triple backticks is:\n",
    "```\n",
    "{}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# It is not specified that it has to be a SELECT query\n",
    "template_no_specification = \"\"\"\n",
    "Write a SPARQL query for querying a graph database.\n",
    "The ontology schema delimited by triple backticks in Turtle format is:\n",
    "```\n",
    "{}\n",
    "```\n",
    "Use only the classes and properties provided in the schema to construct the SPARQL query.\n",
    "Do not use any classes or properties that are not explicitly provided in the SPARQL query.\n",
    "Include all necessary prefixes.\n",
    "Do not include any explanations or apologies in your responses.\n",
    "Do not wrap the query in backticks.\n",
    "Do not include any text except the SPARQL query generated.\n",
    "The question delimited by triple backticks is:\n",
    "```\n",
    "{}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "334b7a80-3717-42fd-a21b-28d0afc5bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-4o-mini\", os.environ.get('FT_MODEL'), \"gpt-4o\"]\n",
    "temperatures = [0, 0.33, 0.66, 1, 1.33]\n",
    "sysmsgs = [sysmsg_tips, sysmsg, sysmsg_new, sysmsg_new_tips]\n",
    "ontologies = [\"ONTOLOGY_V1\", \"ONTOLOGY_V2\", \"NO_NATURAL_LANGUAGE\"]\n",
    "ont_dict = {\"ONTOLOGY_V1\": ontology,\n",
    "            \"ONTOLOGY_V2\": ontology2, \n",
    "            \"NO_NATURAL_LANGUAGE\": ontology3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c20a4-71d6-4614-9537-142f663605ac",
   "metadata": {},
   "source": [
    "### Create dataframe with all different combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4fef4d-9ad2-4d09-83f3-8dc5926fc931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_raw</th>\n",
       "      <th>question_category</th>\n",
       "      <th>variables</th>\n",
       "      <th>gt_query_raw</th>\n",
       "      <th>NUTS level</th>\n",
       "      <th>min inhabitants city</th>\n",
       "      <th>direction</th>\n",
       "      <th>small_distance</th>\n",
       "      <th>big_distance</th>\n",
       "      <th>city_condition</th>\n",
       "      <th>intercardinal</th>\n",
       "      <th>model_str</th>\n",
       "      <th>temperature</th>\n",
       "      <th>sysmsg</th>\n",
       "      <th>template</th>\n",
       "      <th>ontology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are all the NUTS regions that contain the...</td>\n",
       "      <td>simple topology</td>\n",
       "      <td>[CITY]</td>\n",
       "      <td>PREFIX geo: &lt;http://www.opengis.net/ont/geospa...</td>\n",
       "      <td>1</td>\n",
       "      <td>120000</td>\n",
       "      <td>north</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>that are bigger than 99,999</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>You are an AI assistant that translates natura...</td>\n",
       "      <td>template_v1</td>\n",
       "      <td>ONTOLOGY_V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What NUTS regions are within the region CODE?</td>\n",
       "      <td>simple topology</td>\n",
       "      <td>[CODE]</td>\n",
       "      <td>PREFIX geo: &lt;http://www.opengis.net/ont/geospa...</td>\n",
       "      <td>1</td>\n",
       "      <td>120000</td>\n",
       "      <td>west</td>\n",
       "      <td>8</td>\n",
       "      <td>600</td>\n",
       "      <td>that have more than 150000 residents</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>You are an AI assistant that translates natura...</td>\n",
       "      <td>template_v1</td>\n",
       "      <td>ONTOLOGY_V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the NUTS region CODE bordering the region C...</td>\n",
       "      <td>neighbors</td>\n",
       "      <td>[CODE, CODE]</td>\n",
       "      <td>PREFIX geo: &lt;http://www.opengis.net/ont/geospa...</td>\n",
       "      <td>1</td>\n",
       "      <td>120000</td>\n",
       "      <td>north</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>with more than a 120 k people</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>You are an AI assistant that translates natura...</td>\n",
       "      <td>template_v1</td>\n",
       "      <td>ONTOLOGY_V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What regions of the same level are neighbors o...</td>\n",
       "      <td>neighbors</td>\n",
       "      <td>[CODE]</td>\n",
       "      <td>PREFIX geo: &lt;http://www.opengis.net/ont/geospa...</td>\n",
       "      <td>1</td>\n",
       "      <td>120000</td>\n",
       "      <td>west</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>that are bigger than 99,999</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>You are an AI assistant that translates natura...</td>\n",
       "      <td>template_v1</td>\n",
       "      <td>ONTOLOGY_V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the second order neighbors of the sam...</td>\n",
       "      <td>neighbors</td>\n",
       "      <td>[CODE]</td>\n",
       "      <td>PREFIX skos: &lt;http://www.w3.org/2004/02/skos/c...</td>\n",
       "      <td>1</td>\n",
       "      <td>120000</td>\n",
       "      <td>north</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>with more than a 120 k people</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>You are an AI assistant that translates natura...</td>\n",
       "      <td>template_v1</td>\n",
       "      <td>ONTOLOGY_V1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        question_raw question_category  \\\n",
       "0  What are all the NUTS regions that contain the...   simple topology   \n",
       "1      What NUTS regions are within the region CODE?   simple topology   \n",
       "2  Is the NUTS region CODE bordering the region C...         neighbors   \n",
       "3  What regions of the same level are neighbors o...         neighbors   \n",
       "4  What are the second order neighbors of the sam...         neighbors   \n",
       "\n",
       "      variables                                       gt_query_raw NUTS level  \\\n",
       "0        [CITY]  PREFIX geo: <http://www.opengis.net/ont/geospa...          1   \n",
       "1        [CODE]  PREFIX geo: <http://www.opengis.net/ont/geospa...          1   \n",
       "2  [CODE, CODE]  PREFIX geo: <http://www.opengis.net/ont/geospa...          1   \n",
       "3        [CODE]  PREFIX geo: <http://www.opengis.net/ont/geospa...          1   \n",
       "4        [CODE]  PREFIX skos: <http://www.w3.org/2004/02/skos/c...          1   \n",
       "\n",
       "  min inhabitants city direction  small_distance  big_distance  \\\n",
       "0               120000     north               8           500   \n",
       "1               120000      west               8           600   \n",
       "2               120000     north               8           500   \n",
       "3               120000      west               8           500   \n",
       "4               120000     north               8           300   \n",
       "\n",
       "                         city_condition  intercardinal    model_str  \\\n",
       "0           that are bigger than 99,999          False  gpt-4o-mini   \n",
       "1  that have more than 150000 residents          False  gpt-4o-mini   \n",
       "2         with more than a 120 k people          False  gpt-4o-mini   \n",
       "3           that are bigger than 99,999          False  gpt-4o-mini   \n",
       "4         with more than a 120 k people          False  gpt-4o-mini   \n",
       "\n",
       "   temperature                                             sysmsg  \\\n",
       "0          0.0  You are an AI assistant that translates natura...   \n",
       "1          0.0  You are an AI assistant that translates natura...   \n",
       "2          0.0  You are an AI assistant that translates natura...   \n",
       "3          0.0  You are an AI assistant that translates natura...   \n",
       "4          0.0  You are an AI assistant that translates natura...   \n",
       "\n",
       "      template     ontology  \n",
       "0  template_v1  ONTOLOGY_V1  \n",
       "1  template_v1  ONTOLOGY_V1  \n",
       "2  template_v1  ONTOLOGY_V1  \n",
       "3  template_v1  ONTOLOGY_V1  \n",
       "4  template_v1  ONTOLOGY_V1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_combinations_list = []\n",
    "\n",
    "template_d = {sysmsg_new: \"no_sparql_specification_in_prompt_template_beginning\",\n",
    "              sysmsg_new_tips: \"no_sparql_specification_in_prompt_template_beginning\",\n",
    "              sysmsg_tips: 'template_v1',\n",
    "              sysmsg: 'template_v1'}\n",
    "\n",
    "\n",
    "for model, temp, sysmsg, ont in list(product(models, temperatures, sysmsgs, ontologies)):\n",
    "    ex = copy.deepcopy(not_populated)\n",
    "    ex['model_str'] = model\n",
    "    ex['temperature'] = temp\n",
    "    ex['sysmsg'] = sysmsg\n",
    "    ex['template'] = template_d[sysmsg]\n",
    "    ex[\"ontology\"] = ont\n",
    "    all_combinations_list.append(ex)\n",
    "\n",
    "\n",
    "all_combinations = pd.concat(all_combinations_list).reset_index(drop=True)\n",
    "all_combinations.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca26cd-0cfd-4a35-97af-5de4c4ebb393",
   "metadata": {},
   "source": [
    "# SELECT SAMPLE\n",
    "For this demostration the remaining code is only executed with the first 18 questions. The execute the full experiment (19440, plus 9720 for the few-shot experiment), skip the next line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6af4e5a9-7099-438e-b4f9-4a45a25ed540",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combinations = all_combinations.iloc[:18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad920bb-5c29-43d3-9d64-370ad8de10e6",
   "metadata": {},
   "source": [
    "# Populate for RAG experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f401d12-c394-43a5-b6af-5e204513d768",
   "metadata": {},
   "source": [
    "### Populate the questions and ground truth queries with examples\n",
    "Or load existing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6504cd1-451e-48b8-bafb-8ab2f65fb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"data/all_combinations_populated.pkl\"\n",
    "if os.path.exists(fp):\n",
    "    all_combinations_populated = pickleload(fp)\n",
    "else:\n",
    "    all_combinations_populated = copy.deepcopy(all_combinations)\n",
    "    all_combinations_populated[['populated_question', 'populated_gt_query', 'inputs']] = all_combinations_populated.progress_apply(lambda x: populate_question(x), axis=1).values.tolist()\n",
    "    all_combinations_populated = all_combinations_populated.reset_index(drop=True)\n",
    "    pickledump(all_combinations_populated, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d20987-8ce6-4a12-a9fc-3b962a92c4ef",
   "metadata": {},
   "source": [
    "# Get Ground Truth Data\n",
    "Run the ground truth queries for each question to get the correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66ac6ea4-ec7d-4529-adf0-0494e3f9547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"data/all_combinations_populated_with_gt_results.pkl\"\n",
    "if os.path.exists(fp):\n",
    "    all_combinations_populated_with_gt_results = pickleload(fp)\n",
    "else:\n",
    "    all_combinations_populated_with_gt_results = copy.deepcopy(all_combinations_populated)\n",
    "    all_combinations_populated_with_gt_results.loc[:,\"gt_results_from_graph_db\"] = all_combinations_populated_with_gt_results[\"populated_gt_query\"].progress_apply(sparql_select, timeout=500)\n",
    "    pickledump(all_combinations_populated_with_gt_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc02b3-64ef-43ea-a8f5-a118d9a4f791",
   "metadata": {},
   "source": [
    "# Get all LLM responses\n",
    "Or load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dd5e260-3149-4d0f-9fb2-df83d4cd6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"data/with_llm_response.pkl\"\n",
    "if os.path.exists(fp):\n",
    "    with_llm_response = pickleload(fp)\n",
    "else:\n",
    "    with_llm_response = copy.deepcopy(all_combinations_populated_with_gt_results)\n",
    "    with_llm_response.loc[:,[\"answers_raw\", \"tokens_in\", \"tokens_out\"]] = with_llm_response.progress_apply(lambda x: run_client_openai(x['sysmsg'],\\\n",
    "                                                                                                                           template.format(ont_dict[x[\"ontology\"]], x['populated_question']), \\\n",
    "                                                                                                                           model=x['model_str'], temperature=x['temperature'], \\\n",
    "                                                                                                                           max_tokens=800), axis=1).values.tolist()\n",
    "    pickledump(with_llm_response, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7609372-9a30-4e52-9b6d-8516a17d0c4d",
   "metadata": {},
   "source": [
    "# Clean the generated queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14c23714-0869-476d-9da6-1be94d8ebc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 6007.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found nutsdef:notation!, replacing...\n",
      "No prefixes generated, query will fail\n",
      "found nutsdef:notation!, replacing...\n",
      "No prefixes generated, query will fail\n",
      "No prefixes generated, query will fail\n",
      "found nutsdef:notation!, replacing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:01<00:00,  9.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 17967.03it/s]\n"
     ]
    }
   ],
   "source": [
    "with_llm_response.loc[:,\"answers_cleaned\"] = with_llm_response.answers_raw.progress_apply(lambda x: clean_query(x, ontology_g))\n",
    "with_llm_response.loc[:,\"answers_cleaned_replaced\"] = with_llm_response.progress_apply(lambda x: replace_directions_python(x), axis=1)\n",
    "with_llm_response.loc[:,\"answers_cleaned_replaced_optimized\"] = with_llm_response[\"answers_cleaned_replaced\"].progress_apply(lambda x: optimize_buffer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29843d3-1240-4304-ad7e-61f1568d817f",
   "metadata": {},
   "source": [
    "# Get GraphDB results from the generated requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ac7b762-181a-4383-b6d3-d18176664c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"data/with_graph_db_answers.pkl\"\n",
    "if os.path.exists(fp):\n",
    "    with_graph_db_answers = pickleload(fp)\n",
    "else:\n",
    "    with_graph_db_answers = copy.deepcopy(with_llm_response)\n",
    "    with_graph_db_answers.loc[:, \"results_from_graph_db\"] = with_graph_db_answers[\"answers_cleaned_replaced_optimized\"].progress_apply(sparql_select, timeout=500, sleep=0.3)\n",
    "    pickledump(with_graph_db_answers, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7356698-e6ee-4601-b981-efbe2f1a509d",
   "metadata": {},
   "source": [
    "# Run non-RAG LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69c3118c-f29e-4d39-b630-96baeb095ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysmsg_non_rag = \"\"\"You are a helpful assistant that answers questions about the European NUTS regions and cities in Europe.\n",
    "The user will ask questions about topological relationships between the NUTS regions and the cities.\n",
    "\n",
    "If the question asks for NUTS regions your answer should ONLY contain ALL the applicable NUTS codes, for example \"DED, DED4, DED43\" or \"PL91\".\n",
    "If the question asks a true or false question answer ONLY with \"true\" or \"false\".\n",
    "If the question asks for a direction your answer should ONLY contain the applicable direction, for example \"northwest\" or \"south\".\n",
    "If the question asks for a city or multiple cities your answer should ONLY contain the name of the applicable city or ALL applicable cities, for example \"London\" or \"Weilheim i. OB, Deutenhausen, Marnbach\".\n",
    "\n",
    "Do not provide any explanations or apologies.\"\"\"\n",
    "\n",
    "max_tokens_for_non_rag = [100, 500, 50, 100, 200, 50, 50, 50, 50, 50, 500, 1000, 50, 50, 1000, 100, 50, 50]\n",
    "column = max_tokens_for_non_rag * int(len(with_graph_db_answers)/18)\n",
    "with_graph_db_answers['max_tokens_no_rag'] = column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19199140-b75e-4546-a0a0-ae5a48aa8013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:36<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "fp = \"data/with_non_rag_answers.pkl\"\n",
    "if os.path.exists(fp):\n",
    "    all_responses_with_non_rag = pickleload(fp)\n",
    "    # all_responses_with_non_rag = all_responses_with_non_rag.reset_index\n",
    "    # print(\"oanc\")\n",
    "else:\n",
    "    all_responses_with_non_rag = copy.deepcopy(with_graph_db_answers)\n",
    "    all_responses_with_non_rag[['non_rag_answers', 'non_rag_tokens_in', 'non_rag_tokens_out']] = all_responses_with_non_rag.progress_apply(lambda x: run_client_openai(sysmsg, x.populated_question, \\\n",
    "                                                                                                                                                              x.model_str, x.temperature,\\\n",
    "                                                                                                                                                              int(x.max_tokens_no_rag)), axis=1).values.tolist()\n",
    "    pickledump(all_responses_with_non_rag, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd8a24b-dd25-4856-819c-dcbfaaf7e213",
   "metadata": {},
   "source": [
    "# Add few-shotting\n",
    "Due to some difficulties, the same populated questions were used as with the first half of the non-few-shot experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1baf98d-2756-4b34-a966-5cf643b34a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysmsg = \"\"\"You are an AI assistant that writes SPARQL queries to a graph database based on a user question and the graphs' ontology.\n",
    "The questions are about the location and topology of the graphs' elements.\n",
    "Your answer should only contain the SPARQL query.\n",
    "\n",
    "The ontology schema delimited by triple backticks in Turtle format is:\n",
    "```\n",
    "{}\n",
    "```\n",
    "Use only the classes and properties provided in the schema to construct the SPARQL query.\n",
    "Do not use any classes or properties that are not explicitly provided in the SPARQL query.\n",
    "Include all necessary prefixes.\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Write a SPARQL query for querying a graph database.\n",
    "Do not include any explanations or apologies in your responses.\n",
    "Do not wrap the query in backticks.\n",
    "Do not include any text except the SPARQL query generated.\n",
    "The question delimited by triple backticks is:\n",
    "```\n",
    "{}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "ex1 = \"\"\"PREFIX geo: <http://www.opengis.net/ont/geosparql#> \n",
    "PREFIX geof: <http://www.opengis.net/def/function/geosparql/> \n",
    "PREFIX gn: <https://www.geonames.org/ontology#> \n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#> \n",
    "\n",
    "SELECT ?cityName\n",
    "WHERE {\n",
    "    ?city a gn:Feature ;\n",
    "        gn:population ?population ;\n",
    "        gn:name ?cityName ;\n",
    "        geo:hasGeometry ?cityGeom .\n",
    "    ?region a skos:Concept ;\n",
    "        skos:notation \"PL91\" ;\n",
    "        geo:hasGeometry ?regionGeom .\n",
    "    ?cityGeom geo:asWKT ?cityWKT .\n",
    "    ?regionGeom geo:asWKT ?regionWKT .\n",
    "    \n",
    "    BIND(geof:buffer(?regionWKT, 40000) as ?buffer)\n",
    "  \tFILTER(geof:sfWithin(?cityWKT, ?buffer))\n",
    "} \n",
    "ORDER BY DESC(?population)\n",
    "LIMIT 3\"\"\"\n",
    "\n",
    "ex2 = \"\"\"PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX geo: <http://www.opengis.net/ont/geosparql#>\n",
    "PREFIX geof: <http://www.opengis.net/def/function/geosparql/>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "\n",
    "SELECT ?isNorthwestOf WHERE {\n",
    "  ?regionA skos:notation \"DED43\" .\n",
    "  ?regionB skos:notation \"CZ031\" .\n",
    "  ?regionA geo:hasGeometry ?geometryA .\n",
    "  ?regionB geo:hasGeometry ?geometryB .\n",
    "  ?geometryA geo:asWKT ?wktA .\n",
    "  ?geometryB geo:asWKT ?wktB .\n",
    "    BIND(IF(geof:isNorthOf(?wktA, ?wktB) && geof:isWestOf(?wktA, ?wktB), \"True\"^^xsd:boolean, \"False\"^^xsd:boolean) AS ?isNorthwestOf)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def set_up_messages(row):\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": sysmsg.format(ont_dict[row.ontology])\n",
    "    }\n",
    "\n",
    "    examples = [\n",
    "        {\"role\": \"user\", \"content\": \"What are the three largest cities within 40 km of the NUTS region PL91?\"},\n",
    "        {\"role\": \"assistant\", \"content\": ex1},\n",
    "        {\"role\": \"user\", \"content\": \"Is the NUTS region DED43 northwest of the NUTS region CZ031?\"},\n",
    "        {\"role\": \"assistant\", \"content\": ex2}\n",
    "    ]\n",
    "\n",
    "    new_question = {\"role\": \"user\", \"content\": template.format(row.populated_question)}\n",
    "    messages = [system_message] + examples + [new_question]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f539771-d5d3-48fb-8c82-9ff97f8d81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"data/few_shotting.pkl\"\n",
    "if os.path.exists(fp):\n",
    "    to_few_shot = pickleload(fp)\n",
    "else:\n",
    "    to_few_shot = all_responses_with_non_rag[all_responses_with_non_rag.template == \"template_v1\"]\n",
    "    to_few_shot = to_few_shot.drop(columns = [\"answers_raw\", \"tokens_in\", \"tokens_out\", \"answers_cleaned\", \"answers_cleaned_replaced\", \"answers_cleaned_replaced_optimized\", \"results_from_graph_db\", \"sysmsg\", \"template\"])\n",
    "    to_few_shot = to_few_shot.reset_index(drop=True)\n",
    "    to_few_shot[\"template\"] = \"few_shotting\"\n",
    "    to_few_shot[\"sysmsg\"] = \"few_shotting\"\n",
    "    \n",
    "    to_few_shot.loc[:,[\"answers_raw\", \"tokens_in\", \"tokens_out\"]] = to_few_shot.progress_apply(lambda x: run_client_openai(None, None, model=x['model_str'], temperature=x['temperature'], \\\n",
    "                                                                                                         max_tokens=800, few_shotting=set_up_messages(x)), axis=1).values.tolist()\n",
    "    pickledump(to_few_shot, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5abd7237-3640-42b3-99a2-e67c7abc432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_all_answers = pd.concat([all_responses_with_non_rag, to_few_shot])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e274f-937e-465e-913c-aaf617525ff4",
   "metadata": {},
   "source": [
    "### Filter out answers that were generated by \"ASK\" queries\n",
    "ASK queries return in a different format that has to be cleaned first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a171912-fc95-4ea2-90cd-0ac25bedee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_asks(r):\n",
    "    if (type(r) == pd.DataFrame) and (\"{\" in r.columns):\n",
    "        s = r.index[1].replace('\"boolean\" : ', '')\n",
    "        # print(s)\n",
    "        answer = True if \"true\" in s else False\n",
    "        return pd.DataFrame(index = [0], columns = [\"answer\"], data = answer)\n",
    "    else:\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9dca77f2-9615-45c0-9432-fd6c2ad5cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_all_answers[\"results_from_graph_db\"] = with_all_answers[\"results_from_graph_db\"].apply(clean_asks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ad8b1-9683-44ee-afd2-ccfe8c6b7a27",
   "metadata": {},
   "source": [
    "# Save the final results\n",
    "The following line would save the results. The resulting file from this study is provided here instead with the whole amount of 29160 questions. It may be overwritten in case this experiment was run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29ddcfad-61d0-4092-845c-cc3b1a971194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickledump(with_all_answers, f\"data/with_all_answers.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
